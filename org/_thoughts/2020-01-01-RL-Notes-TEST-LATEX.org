#+BEGIN_EXPORT html
---
layout: default
title: RL and LaTeX
math: true
---
#+END_EXPORT

* RL drill
** MDP Bellman Equation for Expected Rewards                         :drill:
:PROPERTIES:
:ID:       70c6b20a-6911-430c-a65e-46f501306957
:END:
- This equation describes the expected reward for taking the action prescribed by some policy $\pi$:
- $V^{\pi}(s) :=$ [$R(s,\pi(s)) + \gamma \Sigma_{s'} P(s'|s, \pi(s)) V^{\pi}(s')$]
** MDP Bellman Optimality Equation                                   :drill:
:PROPERTIES:
:ID:       0bd90849-cd89-4bcf-a0bd-c875eaf1438f
:END:
- This equation describes the reward for taking the action giving the highest expected return. Where $\pi*$ is the optimal policy and $V^{\pi*}$ refers to the value function of the optimal policy:
- $V^{\pi*}(s) :=$ [$\underset{a}{\max} {R(s,a) + \gamma \Sigma_{s'} P(s'|s, a) V^{\pi*}(s')}$]
